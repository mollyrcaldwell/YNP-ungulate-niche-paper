---
title: "YNP Ungulates: phenotype hypervolumes SC version"
author: "Molly Caldwell"
date: "3/3/2023"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, error = FALSE)
knitr::opts_knit$set(root.dir = "C:/Users/mcaldwe2/OneDrive - University of Wyoming/Documents/UWyo/PhD project/YNP-ungulate-niche-paper/")
```

```{r}
library(tidyverse)
library(hypervolume)
library(compiler)
library(foreach)
library(doParallel)
library(progress)
```

#Prep phenotypes per point data

```{r}
#load and prep point phenotype data
phen_pt <- readRDS("./Code Output/all_pts_phen_comb_4.26.2023.rds")

#set geometry to long and lat
phen_pt <- phen_pt %>% 
  mutate(long = unlist(purrr::map(phen_pt$geometry,1)),
           lat = unlist(purrr::map(phen_pt$geometry,2))) 

phen_pt$geometry <- NULL

phen_pt <- as.data.frame(phen_pt)

#pull axes names
axes <- names(select_if(phen_pt, is.double) %>% select(-c("date", "long", "lat", "move_state"))) 

#scale all numeric axes and set move state to factor
phen_pt <- phen_pt %>% 
  mutate_at(axes, ~(scale(as.numeric(.)) %>% as.vector)) %>% 
  mutate(move_state = as.factor(move_state))

#check for NAs 
d_NA <- phen_pt %>% 
  select_if(function(x) any(is.na(x))) %>% 
  summarise_each(funs(sum(is.na(.))))

#remove NAs of NDVI and IRG any season, remove NAs of snowdepth in only winter
phen_pt <- phen_pt %>% 
  drop_na(NDVIVals, IRGVals, move_state, speed) %>% 
  mutate(snowdepth = if_else(is.na(snowdepth) & season == "winter", 9999, snowdepth)) %>% 
  filter(snowdepth != 9999)
```

#Subset data to only days where all individuals per season have data

```{r}
#loop through seasons, subsetting only days where all individuals have data
#create unique season-yr to loop through and date only column
phen_pt <- phen_pt %>% 
  mutate(seas_yr = paste(season, yr, sep = "_"),
         date_only = as.Date(date, tz = "MST"))

u_syr <- unique(phen_pt$seas_yr)

#setup just in time compiler
enableJIT(3)

#prepare parallel processing
  no_cores <- detectCores()-1
  print(paste0("Initiating parallel processing on ", no_cores, " cores."))
  clust <- makeCluster(no_cores) 
  parallel::clusterExport(clust, envir=environment(),
                varlist=c("u_syr", "phen_pt"))

#do call loop
phen_sub <- do.call(rbind, clusterApplyLB(clust, 1:length(u_syr), function(i){
  require("tidyverse")
  
  print(paste0("i: ", i))
  #grab data matching season_yr
  d <- phen_pt %>% filter(seas_yr == u_syr[i])
  
 #summarize number points per day per individual
  d_summ <- d %>% 
    group_by(cid, date_only) %>% 
    summarize(n_pts = n()) %>% 
    ungroup()
  
  #fill in any 0s (days without data)
  d_compl <- d_summ %>% 
    complete(cid, date_only, fill = list(n_pts = 0))
  
  #pull days that any individual has < 6 pts
  i_days <- d_compl %>% 
              filter(n_pts < 6) %>% 
              select(date_only) %>% 
              distinct()
  
  #reduce data set to only days where all individuals have at least 6 pts
  d_sub <- d %>% 
    filter(!date_only %in% i_days$date_only)

  #return subsetted data
  return(d_sub)
  
  }))

stopCluster(clust) #end parallelization

saveRDS(phen_sub, "./Code Output/phenotype_subset_forHypervolumes_5.2.23.rds")

```

#Hypervolume overlap calculations

```{r}
#load subsetted phenotype data if needed
phen_sub <- readRDS("./Code Output/phenotype_subset_forHypervolumes_5.2.23.rds")
```

```{r}
#check correlation move and resource phenotypes
m_pt <- phen_pt %>% 
  select(c(move_state, speed, elev, slope, perc_treecov, snowdepth, swe)) %>% 
  corrr::correlate() #snowdepth and swe highly correlated (0.9). only using snowdepth

r_pt <- phen_pt %>% 
  select(c(IRGVals, NDVIVals)) %>% 
  corrr::correlate()
```

```{r}
#setup just in time compiler
enableJIT(3)

#create data list per season to iterate through
sd_list <- split(phen_sub, f = phen_sub$seas_yr)

#create list of cid pairs per each season
pair_list <- lapply(sd_list, function(x){
  u_ids <- unique(x$cid)
  p_ids <- combn(u_ids, 2)
  return(p_ids)
})

# Prepare parallel processing
no_cores <- detectCores() - 1
cl <- makeCluster(no_cores)
registerDoParallel(cl)
  
  #create list to save data to
  ol_list <- list()
  
  for(i in 1:length(sd_list)){
    print(paste0("i: ", i))
    d <- sd_list[[i]] #select one season-yr dataset
    p_ids <- pair_list[[i]] #pull cid pairs from that seas-yr
    
    # Define the number of iterations
    total <- 2
      #ncol(p_ids)
    
   # setup progress bar for the foreach loop
  #pb <- progress_bar$new(format = "[:bar] :current/:total (:percent)", total = total)
    
  #use foreach to loop through each cid pair and calculate hypervolume overlap
  phen_ol <- foreach(k = 1:2, .combine=rbind,
                     .packages=c("dplyr", "hypervolume")) %dopar% {
    # Update the progress bar
   #pb$tick()
                       
    #extract seas_yr
    syr <- d$seas_yr[1]
    
    #move data
    if (grepl("winter", syr)) {
      md1 <- d %>% filter(cid == p_ids[1, k]) %>% 
        select(c(speed, elev, slope, perc_treecov, snowdepth))
      
      md2 <- d %>% filter(cid == p_ids[2, k]) %>% 
        select(c(speed, elev, slope, perc_treecov, snowdepth))
    } else {
      md1 <- d %>% filter(cid == p_ids[1, k]) %>% 
        select(c(speed, elev, slope, perc_treecov))     
      
      md2 <- d %>% filter(cid == p_ids[2, k]) %>% 
        select(c(speed, elev, slope, perc_treecov))    
    }
    
    #resource data
    rd1 <- d %>% filter(cid == p_ids[1, k]) %>% 
      select(c(long, lat, IRGVals, NDVIVals))
    
    rd2 <- d %>% filter(cid == p_ids[2, k]) %>% 
      select(c(long, lat, IRGVals, NDVIVals))
    
    # Estimate bandwidth for each move and resource dataset
    b_md1 <- estimate_bandwidth(md1)
    b_md2 <- estimate_bandwidth(md2)
    b_rd1 <- estimate_bandwidth(rd1)
    b_rd2 <- estimate_bandwidth(rd2)
    
    # Calculate hypervolumes for each move and resource dataset
    m_hv1 <- hypervolume_gaussian(md1, name = paste(p_ids[1, k], syr, sep = "_"), 
                                  kde.bandwidth = b_md1, 
                                  quantile.requested = 0.9)
    
    m_hv2 <- hypervolume_gaussian(md2, name = paste(p_ids[2, k], syr, sep = "_"), 
                                  kde.bandwidth = b_md2, 
                                  quantile.requested = 0.9)
    
    r_hv1 <- hypervolume_gaussian(rd1, name = paste(p_ids[1, k], syr, sep = "_"), 
                                  kde.bandwidth = b_rd1, 
                                  quantile.requested = 0.9)
                                                    
    r_hv2 <- hypervolume_gaussian(rd2, name = paste(p_ids[2, k], syr, sep = "_"), 
                                  kde.bandwidth = b_rd2, 
                                  quantile.requested = 0.9)
    
  #extract volumes of each hypervolume
  mv1 <- get_volume(m_hv1)
  mv2 <- get_volume(m_hv2)
  rv1 <- get_volume(r_hv1)/(10^6) #reduce resource volume by 10^6 b/c very large with long/lat vals
  rv2 <- get_volume(r_hv2)/(10^6)
  
  #calculate hypervolume overlap for move dataset
  m_ol <- hypervolume_set(m_hv1, m_hv2, check.memory = F)
  m_ol_12 <- m_ol@HVList$Intersection@Volume /mv1
  m_ol_21 <- m_ol@HVList$Intersection@Volume / mv2
  
  #calculate hypervolume overlap for resource dataset
  r_ol <- hypervolume_set(r_hv1, r_hv2, check.memory = F)
  r_ol_12 <- r_ol@HVList$Intersection@Volume / rv1
  r_ol_21 <- r_ol@HVList$Intersection@Volume / rv2
  
  #extract id_yr_seas
  id1 <- paste(p_ids[1, k], syr, sep = "_")
  id2 <- paste(p_ids[2, k], syr, sep = "_")
  
  df <- data.frame(id_yr_seas1 = c(id1, id2), 
                   id_yr_seas2 = c(id2, id1),
                   mov_vol1 = c(mv1, mv2),
                   mov_vol2 = c(mv2, mv1),
                   res_vol1 = c(rv1, rv2),
                   res_vol2 = c(rv2, rv1),
                   move_ol = c(m_ol_12, m_ol_21),
                   res_ol = c(r_ol_12, r_ol_21))
  row.names(df) <- NULL
  
  return(df)
  
  }
  
  #terminate progress bar
  #pb$terminate()
  
ol_list[[i]] <- phen_ol
}

stopCluster(cl) #end parallelization


#combine list elements
ol_comb <- do.call(bind_rows, ol_list)

#export hypervolume overlap data
saveRDS(ol_comb, "./Code Output/phenotype_hypervolume_overlap_all_5.1.2023.rds")

```


```{r}
#for each season-yr, calculate pairwise hypervolume overlap between all individuals
#hypervolume overlap is calculated for 1) movement phenotypes and 2) space/vegetation phenotypes
#subsetted data used (all indiv have at least 6 pts/day per season-yr)

u_syr <- unique(phen_sub$seas_yr) #unique season years to loop through
  
ol_list <- list() #empty list to save output

   #prepare parallel processing
  no_cores <- detectCores()-1
  clust <- makeCluster(no_cores) 
  parallel::clusterExport(clust, envir=environment(),
                varlist=c("u_syr", "phen_sub"))

for(j in 1:2){
  print(paste0("j: ", j))
  
  #grab data matching season_yr
  d <- phen_sub %>% filter(seas_yr == u_syr[j])
  
  u_ids <- unique(d$cid)
  p_ids <- combn(u_ids, 2)
    
  #create temporary list for saving pairwise output
  temp_list <- list()
  
#loop through individuals and calculate hypervolumes and pairwise overlap
  for(k in 1:2){
    print(paste0("k: ", k))
  #extract seas_yr
  syr <- d$seas_yr[1]
  
    #move data
    if(grepl("winter", syr)){
    md1 <- d %>% filter(cid == p_ids[1, k]) %>% 
      select(c(speed, elev, slope, perc_treecov, snowdepth))
    
    md2 <- d %>% filter(cid == p_ids[2, k]) %>% 
      select(c(speed, elev, slope, perc_treecov, snowdepth))
    }else{
    md1 <- d %>% filter(cid == p_ids[1, k]) %>% 
      select(c(speed, elev, slope, perc_treecov))     
    
    md2 <- d %>% filter(cid == p_ids[2, k]) %>% 
      select(c(speed, elev, slope, perc_treecov))    
    }
    
    #resource data
    rd1 <- d %>% filter(cid == p_ids[1, k]) %>% 
      select(c(long, lat, IRGVals, NDVIVals))
    
    rd2 <- d %>% filter(cid == p_ids[2, k]) %>% 
      select(c(long, lat, IRGVals, NDVIVals))
    
    #estimate bandwidth for each move and resource datastet
    b_md1 <- estimate_bandwidth(md1)
    b_md2 <- estimate_bandwidth(md2)
    b_rd1 <- estimate_bandwidth(rd1)
    b_rd2 <- estimate_bandwidth(rd2)
 
    #calculate hypervolumes for each move and resource dataset
    m_hv1 <- hypervolume_gaussian(md1, name = paste(p_ids[1, k], syr, sep = "_"), 
                                  kde.bandwidth = b_md1, 
                                  quantile.requested = 0.9)
    
    m_hv2 <- hypervolume_gaussian(md2, name = paste(p_ids[2, k], syr, sep = "_"), 
                                  kde.bandwidth = b_md2, 
                                  quantile.requested = 0.9)
    
    r_hv1 <- hypervolume_gaussian(rd1, name = paste(p_ids[1, k], syr, sep = "_"), 
                                  kde.bandwidth = b_rd1, 
                                  quantile.requested = 0.9)
    
    r_hv2 <- hypervolume_gaussian(rd2, name = paste(p_ids[2, k], syr, sep = "_"), 
                                  kde.bandwidth = b_rd2, 
                                  quantile.requested = 0.9)
    
  #extract volumes of each hypervolume
  mv1 <- get_volume(m_hv1)
  mv2 <- get_volume(m_hv2)
  rv1 <- get_volume(r_hv1)/(10^6) #reduce resource volume by 10^6 b/c very large with long/lat vals
  rv2 <- get_volume(r_hv2)/(10^6)
  
  #calculate hypervolume overlap for move dataset
  m_ol <- hypervolume_set(m_hv1, m_hv2, check.memory = F)
  m_ol_12 <- m_ol@HVList$Intersection@Volume /mv1
  m_ol_21 <- m_ol@HVList$Intersection@Volume / mv2
  
  #calculate hypervolume overlap for resource dataset
  r_ol <- hypervolume_set(r_hv1, r_hv2, check.memory = F)
  r_ol_12 <- r_ol@HVList$Intersection@Volume / rv1
  r_ol_21 <- r_ol@HVList$Intersection@Volume / rv2
  
  #extract id_yr_seas
  id1 <- paste(p_ids[1, k], syr, sep = "_")
  id2 <- paste(p_ids[2, k], syr, sep = "_")
  
  temp_list[[k]] <- data.frame(id_yr_seas1 = c(id1, id2), 
                   id_yr_seas2 = c(id2, id1),
                   mov_vol1 = c(mv1, mv2),
                   mov_vol2 = c(mv2, mv1),
                   res_vol1 = c(rv1, rv2),
                   res_vol2 = c(rv2, rv1),
                   move_ol = c(m_ol_12, m_ol_21),
                   res_ol = c(r_ol_12, r_ol_21))
  row.names(temp_list[[k]]) <- NULL
  
  }
ol_list[[j]] <- do.call(bind_rows, temp_list)
}

GRstopCluster(clust) #end parallelization


#combine list elements
ol_comb <- do.call(bind_rows, ol_list)

#export hypervolume overlap data
saveRDS(ol_comb, "./Code Output/phenotype_hypervolume_overlap_all_5.1.2023.rds")
```


#extra code

```{r}
b <- phen_pt %>% filter(species == "bison" & yr == 2019 & season == "summer")
e <- phen_pt %>% filter(species == "elk" & yr == 2019 & season == "summer")

b_id <- unique(b$id_yr_seas)
e_id <- unique(e$id_yr_seas)

b <- b %>% filter(id_yr_seas %in% b_id[1:10])
e <- e %>% filter(id_yr_seas %in% e_id[1:15])

b_id <- unique(b$id_yr_seas)
e_id <- unique(e$id_yr_seas)

#hypervolume lists
move_hv_bison <- list()
res_hv_bison <- list()
move_hv_elk <- list()
res_hv_elk <- list()


 ##setup cluster to run on multiple cores
  #set number of cores to use (1 less than you have)
no_cores <- detectCores()-1
# Setup cluster
clust <- makeCluster(no_cores) 
# export the objects you need for your calculations from your environment to each node's environment
clusterExport(clust, varlist=c("b_id", "b", "move_hv_bison", "res_hv_bison",
                               "e_id", "e", "move_hv_elk", "res_hv_elk"))

#bison loop
for(i in 1:length(b_id)){
  print(paste0("bison i: ", i))
  b_dat <- b %>% filter(id_yr_seas == b_id[i])
  
  #move hypervolume
  if(b_dat$season[1] == "winter"){
  move_dat <- b_dat %>% select(c(speed, elev, slope, perc_treecov, snowdepth))
  }else{
    move_dat <- b_dat %>% select(c(speed, elev, slope, perc_treecov))
  }
  
  bwm <- estimate_bandwidth(move_dat)
  move_hv_bison[[i]] <- hypervolume_gaussian(move_dat, name = b_id[i], kde.bandwidth = bwm, 
                                 quantile.requested = 0.9)
  
  #resource hypervolume
  res_dat <- b_dat %>% select(c(long, lat, IRGVals, NDVIVals))
  bwr <- estimate_bandwidth(res_dat)
  res_hv_bison[[i]] <- hypervolume_gaussian(res_dat, name = b_id[i], kde.bandwidth = bwr, 
                                 quantile.requested = 0.9)
  
}

#elk loop
for(i in 1:length(e_id)){
  print(paste0("elk i: ", i))
  e_dat <- e %>% filter(id_yr_seas == e_id[i])
  
  #move hypervolume
  if(e_dat$season[1] == "winter"){
  move_dat <- e_dat %>% select(c(speed, elev, slope, perc_treecov, snowdepth))
  }else{
    move_dat <- e_dat %>% select(c(speed, elev, slope, perc_treecov))
  }
  
  bwm <- estimate_bandwidth(move_dat)
  move_hv_elk[[i]] <- hypervolume_gaussian(move_dat, name = e_id[i], kde.bandwidth = bwm, 
                                 quantile.requested = 0.9)
  
  #resource hypervolume
  res_dat <- e_dat %>% select(c(long, lat, IRGVals, NDVIVals))
  bwr <- estimate_bandwidth(res_dat)
  res_hv_elk[[i]] <- hypervolume_gaussian(res_dat, name = e_id[i], kde.bandwidth = bwr, 
                                 quantile.requested = 0.9)
  
}

 stopCluster(clust)
```

```{r}
#move phenotype hypervolume overlap between bison and elk (pairwise)
#setup just in time compiler
enableJIT(3)
 ##setup cluster to run on multiple cores
  #set number of cores to use (1 less than you have)
no_cores <- detectCores()-1
# Setup cluster
clust <- makeCluster(no_cores) 
# export the objects you need for your calculations from your environment to each node's environment
clusterExport(clust, varlist=c( "move_hv_bison", "res_hv_bison",
                                "move_hv_elk", "res_hv_elk"))
  
#movement phenotype overlap
df_move <- data.frame(id_yr_seas1 = "NA", id_yr_seas2 = "NA",
                   move_ol = NA)

for(i in 1:length(move_hv_bison)){
  print(paste0("move i: ", i))
  b_hv_m <- move_hv_bison[[i]]
  
  for(k in 1:length(move_hv_elk)){
  
  print(paste0("move k: ", k))
  ol <- hypervolume_set(b_hv_m, move_hv_elk[[k]], check.memory = F)
  ol_12 <- ol@HVList$Intersection@Volume / get_volume(b_hv_m)
  ol_21 <- ol@HVList$Intersection@Volume / get_volume(move_hv_elk[[k]])
  id_yr_seas1 <- c(b_hv_m@Name, move_hv_elk[[k]]@Name)
  id_yr_seas2 <- c(move_hv_elk[[k]]@Name, b_hv_m@Name)
  
  df <- data.frame(id_yr_seas1 = id_yr_seas1, id_yr_seas2 = id_yr_seas2,
                   move_ol = c(ol_12, ol_21))

  df_move <- bind_rows(df, df_move)
  
  }
  
}
 

#resource phenotype overlap
df_res <- data.frame(id_yr_seas1 = "NA", id_yr_seas2 = "NA",
                   res_ol = NA)

for(i in 1:length(res_hv_bison)){
  print(paste0("res i: ", i))
  b_hv_r <- res_hv_bison[[i]]
  
  for(k in 1:length(res_hv_elk)){
  
  print(paste0("res k: ", k))
  ol <- hypervolume_set(b_hv_r, res_hv_elk[[k]], check.memory = F)
  ol_12 <- ol@HVList$Intersection@Volume / get_volume(b_hv_r)
  ol_21 <- ol@HVList$Intersection@Volume / get_volume(res_hv_elk[[k]])
  id_yr_seas1 <- c(b_hv_r@Name, res_hv_elk[[k]]@Name)
  id_yr_seas2 <- c(res_hv_elk[[k]]@Name, b_hv_r@Name)
  
  df <- data.frame(id_yr_seas1 = id_yr_seas1, id_yr_seas2 = id_yr_seas2,
                   res_ol = c(ol_12, ol_21))

  df_res <- bind_rows(df, df_res)
  
  }
  
}
stopCluster(clust)

#combine move phenotype and resource overlap to one data frame
bison_elk_ol <- left_join(df_res, df_move, by = c("id_yr_seas1", "id_yr_seas2")) %>% 
  filter(id_yr_seas1 != "NA")
```

```{r}
#subset example dataset for Jared S. meeting
ol_ex <- bison_elk_ol %>% filter(id_yr_seas1 %in% c("BI070_2019_summer", "BI084_2019_summer", "EL1807_2019_summer",
                                                    "EL1902_2019_summer", "EL1628_2019_summer") &
                                   id_yr_seas2 %in% c("BI070_2019_summer", "BI084_2019_summer", "EL1807_2019_summer",
                                                    "EL1902_2019_summer", "EL1628_2019_summer")) %>% 
  arrange(id_yr_seas1, id_yr_seas2) %>% 
  rowwise() %>% 
  mutate(id1 = str_split(id_yr_seas1, "_")[[1]][1],
         id2 = str_split(id_yr_seas2, "_")[[1]][1],
         year = str_split(id_yr_seas1, "_")[[1]][2],
         season = str_split(id_yr_seas1, "_")[[1]][3]) %>% 
  ungroup() %>% 
   mutate(species1 = if_else(grepl("BI", id1), "bison",
                if_else(grepl("BH", id1), "bighorn",
                if_else(grepl("MD", id1), "deer",
                if_else(grepl("EL", id1), "elk",
                if_else(grepl("PR", id1), "pronghorn", "NA")))))) %>%
  mutate(species2 = if_else(grepl("BI", id2), "bison",
                if_else(grepl("BH", id2), "bighorn",
                if_else(grepl("MD", id2), "deer",
                if_else(grepl("EL", id2), "elk",
                if_else(grepl("PR", id2), "pronghorn", "NA")))))) %>% 
  select(-c(id_yr_seas1, id_yr_seas2)) %>% 
  relocate(where(is.numeric), .after = last_col())
  
  
  
  write.table(ol_ex,"./Code Output/move_res_ol_bison_elk_Jared_example_table.txt", row.names=FALSE)
```

```{r}
#plot bison-elk overlap
bison_elk_ol <- bison_elk_ol %>% arrange(id_yr_seas1, id_yr_seas2) %>% 
  rowwise() %>% 
  mutate(id1 = str_split(id_yr_seas1, "_")[[1]][1],
         id2 = str_split(id_yr_seas2, "_")[[1]][1],
         year = str_split(id_yr_seas1, "_")[[1]][2],
         season = str_split(id_yr_seas1, "_")[[1]][3]) %>% 
  ungroup() %>% 
   mutate(species1 = if_else(grepl("BI", id1), "bison",
                if_else(grepl("BH", id1), "bighorn",
                if_else(grepl("MD", id1), "deer",
                if_else(grepl("EL", id1), "elk",
                if_else(grepl("PR", id1), "pronghorn", "NA")))))) %>%
  mutate(species2 = if_else(grepl("BI", id2), "bison",
                if_else(grepl("BH", id2), "bighorn",
                if_else(grepl("MD", id2), "deer",
                if_else(grepl("EL", id2), "elk",
                if_else(grepl("PR", id2), "pronghorn", "NA")))))) %>% 
  select(-c(id_yr_seas1, id_yr_seas2)) %>% 
  relocate(where(is.numeric), .after = last_col())


ggplot(data = bison_elk_ol) +
  geom_point(aes(x = move_ol, y = res_ol, color = id1)) +
  smooth
  facet_wrap(~species1)
```


```{r}
#example movement and res phenotype tables
mv <- phen_pt %>% filter(id_yr_seas == "BI070_2019_summer") %>% select(c(cid, species, date, yr, season, speed, elev, slope, perc_treecov)) %>% 
  mutate(across(c("speed", "elev", "slope", "perc_treecov"), ~ round(.x, digits =3)))

mv <- mv[1:10,]

write.table(mv, "./Code Output/movephen_Jared_exampletable.txt", row.names = F, sep = ",")

res <- phen_pt %>% filter(id_yr_seas == "BI070_2019_summer") %>% select(c(cid, species, date, yr, season, long, lat, NDVIVals, IRGVals)) %>% 
  mutate(across(c(NDVIVals, IRGVals, long, lat), ~round(.x, digits = 3)))

res <- res[1:10,]

write.table(res, "./Code Output/resphen_Jared_exampletable.txt", row.names = F, sep = ",")
```




```{r}
bm <- phen_pt %>% filter(id_yr_seas == "BI070_2019_summer") %>% select(c(speed, elev, slope, perc_treecov))
em <- phen_pt %>% filter(id_yr_seas == "EL1628_2019_summer") %>% select(c(speed, elev, slope, perc_treecov))

bwr <- estimate_bandwidth(bm)
  bm_hv <- hypervolume_gaussian(bm, name = "BI070_2019_summer", kde.bandwidth = bwr, 
                                 quantile.requested = 0.9)
  
  ewr <- estimate_bandwidth(em)
  em_hv <- hypervolume_gaussian(em, name = "EL1628_2019_summer", kde.bandwidth = ewr, 
                                 quantile.requested = 0.9)

plot(hypervolume_join(bm_hv, em_hv), colors = c("red","blue"), 
     show.random = T, show.centroid = FALSE)

hv_s  <- hypervolume_set(bm_hv, em_hv, check.memory = F)

plot(hypervolume_join(bm_hv, em_hv, hv_s[["Intersection"]]), colors = c("red","blue", "purple"), 
     show.random = T, show.centroid = FALSE)

frac_ol12 <- hv_s@HVList$Intersection@Volume / get_volume(bm_hv)
frac_ol21 <- hv_s@HVList$Intersection@Volume / get_volume(em_hv)
```

```{r}
bm <- phen_pt %>% filter(id_yr_seas == "BI070_2019_summer") %>% select(c(long, lat, IRGVals, NDVIVals))
em <- phen_pt %>% filter(id_yr_seas == "EL1628_2019_summer") %>% select(c(long, lat, IRGVals, NDVIVals))

bwr <- estimate_bandwidth(bm)
  bm_hv <- hypervolume_gaussian(bm, name = "BI070_2019_summer", kde.bandwidth = bwr, 
                                 quantile.requested = 0.9)
  
  ewr <- estimate_bandwidth(em)
  em_hv <- hypervolume_gaussian(em, name = "EL1628_2019_summer", kde.bandwidth = ewr, 
                                 quantile.requested = 0.9)

plot(hypervolume_join(bm_hv, em_hv), colors = c("red","blue"), 
     show.random = T, show.centroid = FALSE)

hv_s  <- hypervolume_set(bm_hv, em_hv, check.memory = F)

plot(hypervolume_join(bm_hv, em_hv, hv_s[["Intersection"]]), colors = c("red","blue", "purple"), 
     show.random = T, show.centroid = FALSE)

frac_ol12 <- hv_s@HVList$Intersection@Volume / get_volume(bm_hv)
frac_ol21 <- hv_s@HVList$Intersection@Volume / get_volume(em_hv)
```





```{r}
b <- estimate_bandwidth(d)
b2 <- estimate_bandwidth(d2)

HV_mphen <- hypervolume_gaussian(d, name = "BH01_2017", kde.bandwidth = b, 
                                 quantile.requested = 0.9)

HV_mphen2 <- hypervolume_gaussian(d2, name = "BH02_2017", kde.bandwidth = b2, 
                                 quantile.requested = 0.9)


v1 <- get_volume(HV_mphen)
v2 <- get_volume(HV_mphen2)

plot(hypervolume_join(HV_mphen, HV_mphen2), colors = c("red","blue"), 
     show.random = T, show.centroid = FALSE)


hv_s  <- hypervolume_set(HV_mphen, HV_mphen2, check.memory = F)

plot(hypervolume_join(HV_mphen, HV_mphen2, hv_s[["Intersection"]]), colors = c("red","blue", "purple"), 
     show.random = T, show.centroid = FALSE)

frac_ol <- hv_s@HVList$Intersection@Volume / hv_s@HVList$Union@Volume

ol_stat <- hypervolume_overlap_statistics(hv_s)
```




#Weekly phenotypes

```{r}
#load weekly phenotype data
data <- readRDS("./Code Output/all_wk_move_phen_comb_4.18.2023.rds")

#pull axes names
axes <- names(select_if(data, is.double) %>% select(-c("week", "centralityScaled"))) 

#scale all axes
data <- data %>% 
  mutate_at(axes, ~(scale(as.numeric(.)) %>% as.vector))

#create dataset with only movement 
dm <- data %>% 
  select(c(HR_size_km2, elev_avg, slope_avg, ms_1, perc_treecov_avg, centralityScaled, cid, yr, week))

```




```{r}
b <- estimate_bandwidth(d)
b2 <- estimate_bandwidth(d2)

HV_mphen <- hypervolume_gaussian(d, name = "BH01_2017", kde.bandwidth = b, 
                                 quantile.requested = 0.9)

HV_mphen2 <- hypervolume_gaussian(d2, name = "BH02_2017", kde.bandwidth = b2, 
                                 quantile.requested = 0.9)


v1 <- get_volume(HV_mphen)
v2 <- get_volume(HV_mphen2)

plot(hypervolume_join(HV_mphen, HV_mphen2), colors = c("red","blue"), 
     show.random = T, show.centroid = FALSE)


hv_s  <- hypervolume_set(HV_mphen, HV_mphen2, check.memory = F)

plot(hypervolume_join(HV_mphen, HV_mphen2, hv_s[["Intersection"]]), colors = c("red","blue", "purple"), 
     show.random = T, show.centroid = FALSE)

frac_ol <- hv_s@HVList$Intersection@Volume / hv_s@HVList$Union@Volume

ol_stat <- hypervolume_overlap_statistics(hv_s)
```












