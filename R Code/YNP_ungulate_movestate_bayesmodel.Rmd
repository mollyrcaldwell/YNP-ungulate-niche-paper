---
title: "YNP Ungulate bayesian move states"
author: "Molly Caldwell"
date: "2/27/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, error = FALSE)
knitr::opts_knit$set(root.dir = "~/UWyo/PhD project/YNP-ungulate-niche-paper/")
```

```{r}
#load packages
library(bayesmove)
library(dplyr)
library(ggplot2)
library(purrr)
library(tidyr)
library(lubridate)
library(furrr)
```

#Data prep

```{r}
#load data with movement parameters calculated
data <- readRDS("./Data/allspp_cleanedGPSdata_seasonal_moveparams_3.2022.rds")

#split geometry to x y columns
data <- data %>%
    mutate(x = unlist(purrr::map(geometry,1)),
           y = unlist(purrr::map(geometry,2)))

data$date2 <- NULL

#drop geometry column
data$geometry <- NULL

#rename id_yr_seas to id, dist to SL, and turn angle to TA for bayesmove package
data <- data %>%
  dplyr::rename("id" = id_yr_seas, "SL" = dist, "TA" = rel.angle)

#subset data for trial
#reduce data to 5 random individuals per species
spp <- unique(data$species)
spp_sample <- list()
for(i in 1:length(spp)){
  data_spp <- data.frame(data) %>% dplyr::filter(species == spp[i])
  samp <- sample(unique(data_spp$id), 5)
  
  spp_sample[[i]] <- data.frame(data) %>% filter(id %in% samp)
}

data <- rbind(spp_sample[[1]], spp_sample[[2]], spp_sample[[3]],
                       spp_sample[[4]], spp_sample[[5]])
```

```{r}
#round times and filter to given time step interval (~2 hours for fix rate)

#look at step time interval distribution
hist(data$dt/3600) #most are centered around 2 hour (7200 seconds)
#we want to round observations to fix rate (7200 seconds), with a tolerance of 20 minutes (1200 seconds)
data <- round_track_time(dat = data, id = "id", int = 7200, tol = 1200, time.zone = "MST", units = "secs")

# How many different time intervals?
n_distinct(data$dt)

# How many observations of each time interval?
hist(data$dt, main = "Rounded Time Intervals (s)")
  ##most observations are falling within 2 hr period

#create data list by species
data_spp <- df_to_list(dat = data, ind = "species")

#create listed data by id
data_spp_id <- list()

for(i in 1:length(data_spp)){
data_list <- df_to_list(dat = data_spp[[i]], ind = "id")
data_spp_id[[i]] <- data_list
}

#name listed data by species
names(data_spp_id) <- unique(data$species)

#filter observations to only intervals rounded at 2hr (7200s)
#filtering out ~10,000 out of 1 mill. obs
data_list_filt <- list()

for(i in 1:length(data_spp_id)){
data_list_filt[[i]] <- filter_time(dat.list = data_spp_id[[i]], int = 7200)
}

names(data_list_filt) <- names(data_spp_id)

#check that only observations at 2hr intervals are retained (should only be 1 distinct dt per id)
purrr::map(data_list_filt[[5]], ~n_distinct(.$dt))
```

#Define bins and limits of turn angles and step lengths to inform state models

```{r}
#visualize distribution of turn angles and step lengths by species
for(i in 1:length(data_list_filt)){
sl <- ggplot(bind_rows(data_list_filt[[i]]), aes(x = SL)) + 
  geom_histogram() + 
  ggtitle(paste(names(data_list_filt)[[i]], "step length", sep = " "))
  
ta <- ggplot(bind_rows(data_list_filt[[i]]), aes(x = TA)) + 
  geom_histogram() + 
  ggtitle(paste(names(data_list_filt)[[i]], "turn angle", sep = " "))

print(sl)
print(ta)

}


```

#Defining bins with artificial definition of 'resting' behavior

```{r}
#look at 0.25 quantile
quantile(data_list_filt[[2]][[5]]$SL, 0.25, na.rm = T)

#quantile for 5 bison ranges from 7-103, set resting to 100m
##artificially define resting behavior for each bison
for(i in 1:length(data_list_filt[[2]])){
  data_list_filt[[2]][[i]] <- data_list_filt[[2]][[i]] %>% 
    mutate(SL =  case_when(SL <= 100 ~ 0,
                          SL > 100 ~ SL)
  ) %>%
  mutate(rest = case_when(SL > 100 ~ 2,
                          SL == 0 ~ 1)
  )
}

```

#Defining bins (original)

```{r}
# Define bin number and limits for turning angles by species
angle.bin.lims = seq(from=0, to=360, by=360/4)  #4 bins

# Define bin number and limits for step lengths
dist.bin.lims = quantile(bind_rows(data_list_filt[[2]])$SL,
                        c(0,0.75,1), na.rm=T)  #3 bins
```


#Segment movement states

```{r}
data_list <- data_list_filt[[2]]
#data_list <- data_list[c(1:2)]

#data_list descretize observations to defined bins
#DONT FORGET TO DO THIS, R WILL ABORT if YOU DONT IN THE SEGMENT BEHAVIOR
data_list_d <-  map(data_list,
                       discrete_move_var,
                       lims = list(dist.bin.lims, angle.bin.lims),
                 varIn = c("SL", "TA"),
                 varOut = c("SL1", "TA1"))

# Since 0s get lumped into bin 1 for SL, need to add a 6th bin to store only 0s
data_list_d2 <- data_list_d %>%
  map(., ~mutate(.x, SL1 = SL1 + 1)) %>%  #to shift bins over from 1-5 to 2-6
  map(., ~mutate(.x, SL1 = case_when(SL == 0 ~ 1,  #assign 0s to bin 1
                                    SL != 0 ~ SL1)  #otherwise keep the modified SL bin
                 ))

# Only retain id and discretized step length (SL) and turning angle (TA) columns
data_list2 <- purrr::map(data_list_d2,
                   subset,
                   select = c("id", "SL1", "TA1", "rest"))


# Pre-specify breakpoints based on 'rest'
breaks <- map(data_list2, ~find_breaks(dat = ., ind = "rest"))
```

```{r}
set.seed(1)

# Define hyperparameter for prior distribution
alpha<- 1

# Set number of iterations for the Gibbs sampler
ngibbs<- 50000

# Set the number of bins used to discretize each data stream
nbins<- c(4, 4, 2) #SL, TA, rest bins

progressr::handlers(progressr::handler_progress(clear = FALSE))
future::plan("multicore", workers = availableCores()-2)
#run all MCMC chains in parallel
library(bayesmove)

dat.res<- segment_behavior(data = data_list2, ngibbs = ngibbs, nbins = nbins,
                           alpha = alpha, breakpt = breaks)

future::plan(future::sequential)  #return to single core
```


```{r}
#check that model converged by inspeciting traceplots of number of breakpoints
traceplot(data = dat.res, type = "nbrks")
```


```{r}
#traceplots for the log marginal likelihood per id
traceplot(data = dat.res, type = "LML")
```

```{r}
## Determine MAP for selecting breakpoints
MAP.est<- get_MAP(dat = dat.res$LML, nburn = 25000)
MAP.est
#> [1] 32049 34861 26213

brkpts<- get_breakpts(dat = dat.res$brkpts, MAP.est = MAP.est)

# How many breakpoints estimated per ID?
apply(brkpts[,-1], 1, function(x) length(purrr::discard(x, is.na)))
#> id1 id2 id3 
#>  37  45  40
```


```{r}
#look at breakpoints
plot_breakpoints(data = data_list_d2, as_date = FALSE, var_names = c("SL","TA","rest"),
                 var_labels = c("Step Length (km)", "Turning Angle (rad)", "Resting"), brkpts = brkpts)
```






